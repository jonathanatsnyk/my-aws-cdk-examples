{"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"tags":[],"trusted":true},"source":["\n","# Glue Studio Notebook\n","You are now running a **Glue Studio** notebook; before you can start using your notebook you *must* start an interactive session.\n","\n","## Available Magics\n","|          Magic              |   Type       |                                                                        Description                                                                        |\n","|-----------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| %%configure                 |  Dictionary  |  A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics. |\n","| %profile                    |  String      |  Specify a profile in your aws configuration to use as the credentials provider.                                                                          |\n","| %iam_role                   |  String      |  Specify an IAM role to execute your session with.                                                                                                        |\n","| %region                     |  String      |  Specify the AWS region in which to initialize a session                                                                                                  |\n","| %session_id                 |  String      |  Returns the session ID for the running session.                                                                                                          |\n","| %connections                |  List        |  Specify a comma separated list of connections to use in the session.                                                                                     |\n","| %additional_python_modules  |  List        |  Comma separated list of pip packages, s3 paths or private pip arguments.                                                                                 |\n","| %extra_py_files             |  List        |  Comma separated list of additional Python files from S3.                                                                                                 |\n","| %extra_jars                 |  List        |  Comma separated list of additional Jars to include in the cluster.                                                                                       |\n","| %number_of_workers          |  Integer     |  The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too.                                          |\n","| %worker_type                |  String      |  Standard, G.1X, *or* G.2X. number_of_workers must be set too. Default is G.1X                                                                            |\n","| %glue_version               |  String      |  The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0 (eg: %glue_version 2.0)                                |\n","| %security_configuration     |  String      |  Define a security configuration to be used with this session.                                                                                            |\n","| %sql                        |  String      |  Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code.                                                            |\n","| %streaming                  |  String      |  Changes the session type to Glue Streaming.                                                                                                              |\n","| %etl                        |  String      |   Changes the session type to Glue ETL.                                                                                                                   |\n","| %status                     |              |  Returns the status of the current Glue session including its duration, configuration and executing user / role.                                          |\n","| %stop_session               |              |  Stops the current session.                                                                                                                               |\n","| %list_sessions              |              |  Lists all currently running sessions by name and ID.                                                                                                     |"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to the Glue Interactive Sessions Kernel\n","For more information on available magic commands, please type %help in any new cell.\n","\n","Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n","It looks like there is a newer version of the kernel available. The latest version is 0.32 and you have 0.30 installed.\n","Please run `pip install --upgrade aws-glue-sessions` to upgrade your kernel\n","Setting Glue version to: 3.0\n","Current idle_timeout is None minutes.\n","idle_timeout has been set to 60 minutes.\n","Connections to be included:\n","iceberg-connection\n","The following configurations have been updated: {'--conf': 'spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions'}\n"]}],"source":["%glue_version 3.0\n","%idle_timeout 60\n","%connections iceberg-connection\n","%%configure\n","{\n","  \"--conf\": \"spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\n","}"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["There is no current session.\n"]}],"source":["%session_id"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::123456789012:role/GlueJobRole\n","Attempting to use existing AssumeRole session credentials.\n","Trying to create a Glue session for the kernel.\n","Worker Type: G.1X\n","Number of Workers: 5\n","Session ID: 8f744449-499c-4f28-88b9-cfd432357b15\n","Applying the following default arguments:\n","--glue_kernel_version 0.30\n","--enable-glue-datacatalog true\n","--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\n","Waiting for session 8f744449-499c-4f28-88b9-cfd432357b15 to get into ready status...\n","Session 8f744449-499c-4f28-88b9-cfd432357b15 has been created\n","\n","\n"]}],"source":["RAW_S3_PATH = 's3://aws-glue-input-parquet-atq4q5u/full-load/human_resources/employee_details/'\n","CATALOG = 'glue_catalog'\n","ICEBERG_S3_PATH = 's3://aws-glue-output-iceberg-atq4q5u'\n","DATABASE = 'human_resources'\n","TABLE_NAME = 'employee_details_iceberg'\n","PK = 'emp_no'\n","PARTITION = 'department'\n","DYNAMODB_LOCK_TABLE = 'employee_details_lock'"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Current active Session ID: 8f744449-499c-4f28-88b9-cfd432357b15\n"]}],"source":["%session_id"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["spark.stop()\n","sc.stop()"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["import sys\n","from datetime import datetime\n","\n","from awsglue.transforms import *\n","from awsglue.utils import getResolvedOptions\n","from pyspark.context import SparkContext\n","from awsglue.context import GlueContext\n","from awsglue.job import Job\n","from awsglue.dynamicframe import DynamicFrame\n","\n","from pyspark.conf import SparkConf\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import (\n","  concat,\n","  col,\n","  lit,\n","  max,\n","  rank,\n","  to_timestamp\n",")\n","\n","conf = SparkConf()\n","\n","conf.set(f\"spark.sql.catalog.{CATALOG}\", \"org.apache.iceberg.spark.SparkCatalog\")\n","conf.set(f\"spark.sql.catalog.{CATALOG}.warehouse\", ICEBERG_S3_PATH)\n","conf.set(f\"spark.sql.catalog.{CATALOG}.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\")\n","conf.set(f\"spark.sql.catalog.{CATALOG}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n","conf.set(f\"spark.sql.catalog.{CATALOG}.lock-impl\", \"org.apache.iceberg.aws.glue.DynamoLockManager\")\n","conf.set(f\"spark.sql.catalog.{CATALOG}.lock.table\", DYNAMODB_LOCK_TABLE)\n","conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n","conf.set(\"spark.sql.iceberg.handle-timestamp-without-timezone\",\"true\")\n","\n","glueContext = GlueContext(SparkContext(conf=conf))\n","spark = glueContext.spark_session"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["cdcDynamicFrame = glueContext.create_dynamic_frame_from_options(\n","  connection_type='s3',\n","  connection_options={\n","    'paths': [f'{RAW_S3_PATH}'],\n","    'groupFiles': 'none',\n","    'recurse': True\n","  },\n","  format='parquet',\n","  transformation_ctx='cdcDyf')"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Count of CDC data after last job bookmark:5\n"]}],"source":["print(f\"Count of CDC data after last job bookmark:{cdcDynamicFrame.count()}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Op: string (nullable = true)\n"," |-- emp_no: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- salary: integer (nullable = true)\n"," |-- m_time: timestamp (nullable = true)\n"]}],"source":["cdcDF = cdcDynamicFrame.toDF()\n","cdcDF.printSchema()"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Op: string (nullable = true)\n"," |-- emp_no: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- salary: integer (nullable = true)\n"," |-- m_time: timestamp (nullable = true)\n"]}],"source":["cdcDF = cdcDF.withColumn('m_time', to_timestamp(col('m_time')))\n","cdcDF.printSchema()"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Op: string (nullable = true)\n"," |-- emp_no: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- salary: integer (nullable = true)\n"," |-- m_time: timestamp (nullable = true)\n"," |-- max_op_date: timestamp (nullable = true)\n"]}],"source":["IDWindowDF = Window.partitionBy(cdcDF.emp_no).orderBy(cdcDF.m_time).rangeBetween(-sys.maxsize, sys.maxsize)\n","inputDFWithTS = cdcDF.withColumn(\"max_op_date\", max(cdcDF.m_time).over(IDWindowDF))\n","inputDFWithTS.printSchema()"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Op: string (nullable = true)\n"," |-- emp_no: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- salary: integer (nullable = true)\n"," |-- m_time: timestamp (nullable = true)\n"," |-- max_op_date: timestamp (nullable = true)\n"]}],"source":["newInsertedDF = inputDFWithTS.filter(\"m_time=max_op_date\").filter(\"Op='I'\")\n","updatedOrDeletedDF = inputDFWithTS.filter(\"m_time=max_op_date\").filter(\"Op IN ('U', 'D')\")\n","finalInputDF = newInsertedDF.unionAll(updatedOrDeletedDF)\n","finalInputDF.printSchema()"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Op: string (nullable = true)\n"," |-- emp_no: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- department: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- salary: integer (nullable = true)\n"," |-- m_time: timestamp (nullable = true)\n"," |-- max_op_date: timestamp (nullable = true)\n"," |-- last_applied_date: timestamp (nullable = true)\n"]}],"source":["CURRENT_DATETIME = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","finalInputDF = finalInputDF.withColumn('last_applied_date', to_timestamp(lit(CURRENT_DATETIME)))\n","finalInputDF.printSchema()"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Inserted count:  2\n","Updated count:   2\n","Deleted count:   1\n","Total CDC count: 5\n"]}],"source":["cdcInsertCount = finalInputDF.filter(\"Op = 'I'\").count()\n","cdcUpdateCount = finalInputDF.filter(\"Op = 'U'\").count()\n","cdcDeleteCount = finalInputDF.filter(\"Op = 'D'\").count()\n","totalCDCCount = finalInputDF.count()\n","\n","print(f\"Inserted count:  {cdcInsertCount}\")\n","print(f\"Updated count:   {cdcUpdateCount}\")\n","print(f\"Deleted count:   {cdcDeleteCount}\")\n","print(f\"Total CDC count: {totalCDCCount}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["['employee_details_iceberg']\n"]}],"source":["tablesDF = spark.sql(f\"SHOW TABLES IN {DATABASE}\")\n","table_list = tablesDF.select('tableName').rdd.flatMap(lambda x: x).collect()\n","table_list"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["dropColumnList = ['Op', 'schema_name', 'table_name', 'max_op_date']"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n"]}],"source":["upsertedDF = finalInputDF.filter(\"Op != 'D'\").drop(*dropColumnList)\n","upsertedDF.count()"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["upsertedDF.createOrReplaceTempView(f\"{TABLE_NAME}_upsert\")"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame[]\n"]}],"source":["spark.sql(f\"\"\"MERGE INTO {CATALOG}.{DATABASE}.{TABLE_NAME} t\n","        USING {TABLE_NAME}_upsert s ON s.{PK} = t.{PK}\n","        WHEN MATCHED THEN UPDATE SET *\n","        WHEN NOT MATCHED THEN INSERT *\n","        \"\"\")"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["deletedDF = finalInputDF.filter(\"Op = 'D'\").drop(*dropColumnList)\n","deletedDF.count()"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["deletedDF.createOrReplaceTempView(f\"{TABLE_NAME}_delete\")"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame[]\n"]}],"source":["spark.sql(f\"\"\"MERGE INTO {CATALOG}.{DATABASE}.{TABLE_NAME} t\n","        USING {TABLE_NAME}_delete s ON s.{PK} = t.{PK}\n","        WHEN MATCHED THEN DELETE\n","        \"\"\")"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+-----+-------------+---------+------+-------------------+-------------------+\n","|emp_no| name|   department|     city|salary|             m_time|  last_applied_date|\n","+------+-----+-------------+---------+------+-------------------+-------------------+\n","|     9|  Eli|   Purchasing|  Chicago| 90000|2022-07-29 07:44:34|2022-08-21 05:55:04|\n","|     2|Susan|        Sales|New Delhi| 60000|2022-07-24 15:17:36|2022-08-21 05:55:04|\n","|     5|  Joe|           IT|  Chicago| 70000|2022-07-24 15:18:04|2022-08-21 05:55:04|\n","|     8| John|        Sales|      SFO| 90000|2022-07-29 07:44:20|2022-08-21 05:55:04|\n","|     4| Bill|Manufacturing|New Delhi| 70000|2022-07-24 15:17:54|2022-08-14 13:15:59|\n","+------+-----+-------------+---------+------+-------------------+-------------------+\n"]}],"source":["spark.sql(f\"SELECT * FROM {CATALOG}.{DATABASE}.{TABLE_NAME} limit 5\").show()"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true,"vscode":{"languageId":"python_glue_session"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Total count of employee_details_iceberg Table Results:\n","\n","+--------+\n","|count(1)|\n","+--------+\n","|       8|\n","+--------+\n","\n","None\n"]}],"source":["print(f\"Total count of {TABLE_NAME} Table Results:\\n\")\n","countDF = spark.sql(f\"SELECT count(*) FROM {CATALOG}.{DATABASE}.{TABLE_NAME}\")\n","print(f\"{countDF.show()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python_glue_session"}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Glue PySpark","language":"python","name":"glue_pyspark"},"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"Python_Glue_Session","pygments_lexer":"python3"}},"nbformat":4,"nbformat_minor":4}
